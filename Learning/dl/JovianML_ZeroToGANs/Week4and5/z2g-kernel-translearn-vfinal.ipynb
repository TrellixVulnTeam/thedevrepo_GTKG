{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import os\nimport torch\nimport torchvision\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom tqdm.notebook import tqdm\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DATA_DIR = '../input/jovian-pytorch-z2g/Human protein atlas'\n\nTRAIN_DIR = DATA_DIR + '/train'                           \nTEST_DIR = DATA_DIR + '/test'                             \n\nTRAIN_CSV = DATA_DIR + '/train.csv'                       \nTEST_CSV = '../input/jovian-pytorch-z2g/submission.csv' ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"csv = pd.read_csv(TRAIN_CSV)\ncsv.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = {\n    0: 'Mitochondria',\n    1: 'Nuclear bodies',\n    2: 'Nucleoli',\n    3: 'Golgi apparatus',\n    4: 'Nucleoplasm',\n    5: 'Nucleoli fibrillar center',\n    6: 'Cytosol',\n    7: 'Plasma membrane',\n    8: 'Centrosome',\n    9: 'Nuclear speckles'\n}\n\nnum_cls = len(labels)\nprint(\"Num classes: {}\".format(num_cls))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nencode_lbl\n\ntarget: target from the dataset\nkeys: dictionary of classes {id:label}\n\nexample -- [2 4 5] => [0 0 1 0 1 1 0 0 0 0] \n\n\"\"\"\ndef encode_lbl(target, keys=labels):\n    \n    ohv = torch.zeros(num_cls)\n    for cls_id in str(target).split(' '):\n        ohv[int(cls_id)] = 1\n    \n    return ohv\n            \n\"\"\"\ndecode_lbl\n\ny: target from the dataset/prediction\nkeys: dictionary of classes {id:label}\nshow_lbl: Boolean flag to show/hide text label\nthreshold: Threshold to assign class label\n\n\"\"\"\ndef decode_lbl(y, keys=labels, show_lbl=False, threshold=0.5):\n    \n    result = []\n    for i,v in enumerate(y):\n        if (v >= threshold):\n            if show_lbl:\n                result.append(keys[i] + '-' + str(i))\n            else:\n                result.append(str(i))\n        \n    return ' '.join(result)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a = encode_lbl('2 4 5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"decode_lbl(a, show_lbl=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dataset enhancement\n\n\"\"\"\nHumanProteinDataset\n\nReads the image based on the id from dataframe and the dir path.\nReturns the (transformed) image along with encoded label.\n\"\"\"\nclass HumanProteinDataset(Dataset):\n    \n    def __init__(self, df, base_dir, tsfm=None):\n        self.df = df\n        self.base_dir = base_dir\n        self.tsfm = tsfm\n    \n    def __len__(self):\n        return len(self.df)\n        \n    def __getitem__(self, idx):\n        \n        obs = self.df.loc[idx]\n        img_id, img_lbl = obs['Image'], obs['Label']\n        im_path = os.path.join(self.base_dir, str(img_id)+\".png\")\n        \n        img = Image.open(im_path)\n        if self.tsfm:\n            img = self.tsfm(img)\n        \n        return img, encode_lbl(img_lbl)\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imagenet_stats = ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n\ntrain_tfms = torchvision.transforms.Compose([\n    torchvision.transforms.RandomCrop(512, padding=8, padding_mode='reflect'),\n#     torchvision.transforms.RandomResizedCrop(256, scale=(0.5,0.9), ratio=(1, 1)), \n#     torchvision.transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n    torchvision.transforms.RandomHorizontalFlip(), \n    torchvision.transforms.RandomRotation(10),\n    torchvision.transforms.ToTensor(), \n    torchvision.transforms.Normalize(*imagenet_stats,inplace=True), \n#     torchvision.transforms.RandomErasing(inplace=True)\n])\n\nvalid_tfms = torchvision.transforms.Compose([\n#     torchvision.transforms.Resize(256), \n    torchvision.transforms.ToTensor(), \n    torchvision.transforms.Normalize(*imagenet_stats)\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.random.seed(42)\ntrain_idx = np.random.random(csv.shape[0]) < 0.9\n\ntrain_csv = csv[train_idx].reset_index(drop=True)\nval_csv = csv[~train_idx].reset_index(drop=True)\n\nprint(train_csv.shape[0], val_csv.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_csv.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_ds = HumanProteinDataset(train_csv, TRAIN_DIR, train_tfms)\nval_ds = HumanProteinDataset(val_csv, TRAIN_DIR, valid_tfms)\n\nprint(len(train_ds[0]), len(val_ds[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_csv = pd.read_csv(TEST_CSV)\ntest_dataset = HumanProteinDataset(test_csv, TEST_DIR, valid_tfms)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_csv.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_sample(img, target, invert=False):\n    \n    if invert:\n        plt.imshow(1 - img.permute(1, 2, 0))\n    else:\n        plt.imshow(img.permute(1, 2, 0))\n        \n    print(\"Label: {}\".format(decode_lbl(target, show_lbl=True)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_sample(*train_ds[10])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_sample(*train_ds[10], invert=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 16\n\ntrain_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\nval_dl = DataLoader(val_ds, batch_size=batch_size*2, shuffle=True, num_workers=3, pin_memory=True)\n\ntest_dl = DataLoader(test_dataset, batch_size, num_workers=3, pin_memory=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def F_score(output, label, threshold=0.5, beta=1):\n    prob = output > threshold\n    label = label > threshold\n\n    TP = (prob & label).sum(1).float()\n    TN = ((~prob) & (~label)).sum(1).float()\n    FP = (prob & (~label)).sum(1).float()\n    FN = ((~prob) & label).sum(1).float()\n\n    precision = torch.mean(TP / (TP + FP + 1e-12))\n    recall = torch.mean(TP / (TP + FN + 1e-12))\n    F2 = (1 + beta**2) * precision * recall / (beta**2 * precision + recall + 1e-12)\n    return F2.mean(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class MultilabelImageClassificationBase(torch.nn.Module):\n    def training_step(self, batch):\n        images, targets = batch \n        out = self(images)                      \n        loss = F.binary_cross_entropy(out, targets)      \n        return loss\n    \n    def validation_step(self, batch):\n        images, targets = batch \n        out = self(images)                           # Generate predictions\n        loss = F.binary_cross_entropy(out, targets)  # Calculate loss\n        score = F_score(out, targets)\n        return {'val_loss': loss.detach(), 'val_score': score.detach() }\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        batch_scores = [x['val_score'] for x in outputs]\n        epoch_score = torch.stack(batch_scores).mean()      # Combine accuracies\n        return {'val_loss': epoch_loss.item(), 'val_score': epoch_score.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_score: {:.4f}\".format(\n            epoch, result['train_loss'], result['val_loss'], result['val_score']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class ProteinClassifierTransLearn(MultilabelImageClassificationBase):\n    def __init__(self):\n        super().__init__()\n        # Use a pretrained model\n        self.network = torchvision.models.resnet34(pretrained=True)\n        # Replace last layer\n        num_ftrs = self.network.fc.in_features\n        self.network.fc = torch.nn.Linear(num_ftrs, 10)\n    \n    def forward(self, xb):\n        return torch.sigmoid(self.network(xb))                ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef get_default_device():\n    \"\"\"Pick GPU if available, else CPU\"\"\"\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n    \ndef to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl: \n            yield to_device(b, self.device)\n\n    def __len__(self):\n        \"\"\"Number of batches\"\"\"\n        return len(self.dl)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = get_default_device()\ndevice","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dl = DeviceDataLoader(train_dl, device)\nval_dl = DeviceDataLoader(val_dl, device)\ntest_dl = DeviceDataLoader(test_dl, device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"@torch.no_grad()\ndef evaluate(model, val_loader):\n    model.eval()\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\ndef fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n    torch.cuda.empty_cache()\n    history = []\n    optimizer = opt_func(model.parameters(), lr)\n    for epoch in range(epochs):\n        # Training Phase \n        model.train()\n        train_losses = []\n        for batch in tqdm(train_loader):\n            loss = model.training_step(batch)\n            train_losses.append(loss)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n        # Validation phase\n        result = evaluate(model, val_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        model.epoch_end(epoch, result)\n        history.append(result)\n    return history","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_lr(optimizer):\n    for param_group in optimizer.param_groups:\n        return param_group['lr']\n\ndef fit_one_cycle(epochs, max_lr, model, train_loader, val_loader, weight_decay=0, grad_clip=None, opt_func=torch.optim.SGD):\n    \n    torch.cuda.empty_cache()\n    history = []\n    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n    \n    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, steps_per_epoch=len(train_loader))\n    \n    for e in range(epochs):\n        \n        model.train()\n        train_losses = []\n        lrs = []\n        \n        for batch in train_loader:\n            losses = model.training_step(batch)\n            \n            train_losses.append(losses)\n            losses.backward()\n            \n            if grad_clip:\n                torch.nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n            \n            optimizer.step()\n            optimizer.zero_grad()\n            \n            lrs.append(get_lr(optimizer))\n            sched.step()\n            \n        result = evaluate(model, val_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        result['lrs'] = lrs\n        \n        model.epoch_end(e, result)\n        history.append(result)\n        \n    return history","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = to_device(ProteinClassifierTransLearn(), device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"@torch.no_grad()\ndef predict_dl(dl, model):\n\n    torch.cuda.empty_cache()\n\n    batch_probs = []\n    for xb, _ in dl:\n        probs = model(xb)\n        batch_probs.append(probs.cpu().detach())\n    batch_probs = torch.cat(batch_probs)\n    return [decode_lbl(x) for x in batch_probs]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = [evaluate(model, val_dl)]\n\nhistory","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 2\nmax_lr = 5e-3\ngrad_clip = 0.1\nweight_decay = 1e-4\nopt_func = torch.optim.Adam","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# history += fit(epochs, max_lr, model, train_dl, val_dl, opt_func=torch.optim.Adam)\nhistory += fit_one_cycle(epochs, max_lr, model, train_dl, val_dl, weight_decay=weight_decay, grad_clip=grad_clip, opt_func=opt_func)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"weights_fname = 'protein-resnet.pth'\ntorch.save(model.state_dict(), weights_fname)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_preds = predict_dl(test_dl, model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_preds[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df = pd.read_csv(TEST_CSV)\nsubmission_df.Label = test_preds\n\nprint(submission_df.head())\nsub_fname = 'resnet_submission.csv'\nsubmission_df.to_csv(sub_fname, index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df.to_csv('/kaggle/working/kaggle_submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}